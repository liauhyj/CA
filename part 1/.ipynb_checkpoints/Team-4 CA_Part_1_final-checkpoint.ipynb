{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA51 Team 4 Python Machine Learning CA - Part 1\n",
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wines are produced across various regions and appreciated by people all over the world.\n",
    "\n",
    "Data on the attributes that may possibly shape the taste character of red wine has been collected. Wine experts were recruited to grade the wine quality of each sample between 0 (very bad) and 10 (very excellent) and the median of at least 3 evaluations made by experts for each sample is also included in the dataset.\n",
    "\n",
    "The objective of this report is to investigate:\n",
    "\n",
    "(a) The relationships between wine attributes and the quality, which is a representation of consumer preferences; and \n",
    "(b) the viability of classifying red wine into the different quality grades based these attributes.\n",
    "\n",
    "The aim is to explore whether consumer preferences can be transformed into measurable indicators that may be used during the wine production process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classification models will be explored, along with data engineering and feature engineering in the second half of the report. \n",
    "\n",
    "1.Logistic Regression (LogReg) Model\n",
    "\n",
    "2.K-Nearest Neighbours (K-NN) Model\n",
    "\n",
    "3.Decision Tree (DT) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source of the original dataset is from: https://www.kaggle.com/danielpanizzo/wine-quality. Only the dataset for red wine consisting of 1599 samples is used for the purposes of this report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The independent variables of red wine in relation to its quality will be explored. These variables are:\n",
    "\n",
    "1 - fixed acidity (tartaric acid - g / dm^3) - most acids involved with wine or fixed or nonvolatile  \n",
    "\n",
    "2 - volatile acidity (acetic acid - g / dm^3) - the amount of acetic acid in wine, which at too high of levels can lead to an       unpleasant, vinegar taste \n",
    "\n",
    "3 - citric acid (g / dm^3) - found in small quantities, citric acid can add 'freshness' and flavor to wines\n",
    "\n",
    "4 - residual sugar (g / dm^3) - the amount of sugar remaining after fermentation stops, it's rare to find wines with less than 1     gram/liter and wines with greater than 45 grams/liter are considered sweet\n",
    "\n",
    "5 - chlorides (sodium chloride - g / dm^3) - the amount of salt in the wine\n",
    "\n",
    "6 - free sulfur dioxide (mg / dm^3) - the free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and     bisulfite ion; it prevents microbial growth and the oxidation of wine\n",
    "\n",
    "7 - total sulfur dioxide (mg / dm^3) - ,the amount of free and bound forms of S02; in low concentrations, SO2 is mostly undetectable     in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine\n",
    "\n",
    "8 - density (g / cm^3) - the density of water is close to that of water depending on the percent alcohol and sugar content\n",
    "\n",
    "9 - pH - describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic); most wines are between 3-4     on the pH scale\n",
    "\n",
    "10 - sulphates (potassium sulphate - g / dm3) - a wine additive which can contribute to sulfur dioxide gas (S02) levels, wich        acts as an antimicrobial and antioxidant\n",
    "\n",
    "11 - alcohol (% by volume) - the percent alcohol content of the wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependent variable will stand as:\n",
    "\n",
    "1 - quality (score between 0 and 10) - based on sensory data; median of at least 3 evaluations made by wine experts (Note: only grades of 3 to 8 are present in the dataset as the results of rating only fall within that range) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'counter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6ecacfb49dce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'counter'"
     ]
    }
   ],
   "source": [
    "# Import the modules required to process this project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import graphviz\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "import counter\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv data file\n",
    "df = pd.read_csv(\"data/wine quality - red.csv\")\n",
    "# Show the independent and dependent variables in table form\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we print the shape of the data file in (rows,columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the inplace = True command, we compare and observe that the shape remains the same as before.\n",
    "# Hence, there are no null values\n",
    "df.dropna(inplace = True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the features without target\n",
    "x = df.iloc[:,:-1] \n",
    "# Read the last column,'quality' as the target\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 0, stratify = y)\n",
    "# stratify = y is used to ensure the proportion of all classes are the same in both training and test sets\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Model Training and Prediction prior to Data and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Accuracy: 0.625)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training set\n",
    "\n",
    "logReg = LogisticRegression (solver = 'lbfgs', multi_class = 'auto', random_state = 0, max_iter = 8000) \n",
    "# The maximum number of iterations has been raised as the default 100 iterations is insufficient \n",
    "# for model to converge given the multiple classes and features\n",
    "\n",
    "start_time = time.time()\n",
    "logReg.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "print('For Logistic Regression, training the model takes %s seconds.'%time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model using the test dataset\n",
    "# Calculate the duration for prediction and the accuracy of the model\n",
    "start_time = time.time()\n",
    "y_pred = logReg.predict(x_test)\n",
    "end_time = time.time() \n",
    "time_taken = end_time - start_time\n",
    "print('For Logistic Regression, prediction takes %s seconds.' %time_taken)\n",
    "print('For Logistic Regression, accuracy score: %s.' %accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model's confusion matrix\n",
    "confusion_matrix (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Classification (Accuracy: 0.515)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the various k values in an array\n",
    "k_array=np.arange(3,21,2) \n",
    "k_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding k with the highest accuracy for values in k_array\n",
    "\n",
    "k_max = 0\n",
    "ac_max = 0\n",
    "\n",
    "for k in k_array:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train,y_train)\n",
    "    accuracy = accuracy_score(y_test, knn.predict(x_test))\n",
    "    if (accuracy > ac_max):\n",
    "        k_max = k\n",
    "        ac_max = accuracy\n",
    "    print(\"k =\", k, \"and accuracy =\", accuracy)\n",
    "print(\"----------\")\n",
    "print(\"The number of neighbours with the best accuracy for K-NN is\", k_max, \"of accuracy\", ac_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 1 is excluded to avoid overfitting. k = 19 has the highest accuracy for odd numbers between 3 (inclusive) and 20. We have only considered odd numbers between 3 (inclusive) and 20 as the computational load increases exponentially as k increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model K-NN with k = 19 neighbours\n",
    "knn_1 = KNeighborsClassifier(n_neighbors=k_max)\n",
    "\n",
    "start_time = time.time()\n",
    "knn_1.fit(x_train,y_train)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"For K-NN, training the model takes %s seconds.\" %time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model using the test dataset\n",
    "# Calculate the duration for prediction and the accuracy of the model\n",
    "start_time = time.time()\n",
    "y_pred = knn_1.predict(x_test)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"For K-NN, prediction takes %s seconds.\" %time_taken)\n",
    "print(\"For K-NN, accuracy score: %s\" %accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model's confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (Accuracy: 0.6275)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training set\n",
    "dt = DecisionTreeClassifier(random_state = 0)\n",
    "\n",
    "start_time = time.time()\n",
    "dt.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"For Decision Tree, training the model takes %s seconds\" %time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model using the test dataset\n",
    "# Calculate the duration for prediction and the accuracy of the model\n",
    "start_time = time.time()\n",
    "y_pred = dt.predict(x_test)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"For Decision Tree, prediction takes %s seconds.\" %time_taken)\n",
    "print(\"For Decision Tree, accuracy score: %s\" %accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model's confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tree, with no output file\n",
    "\n",
    "Source(tree.export_graphviz(dt, out_file=None, class_names=[\"3\", \"4\", \"5\", \"6\", \"7\", \"8\"], \n",
    "                            feature_names= x_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering - Dealing with Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will explore how data engineering via data sampling could possibly lessen the bias caused by an imbalanced dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the above chart on the distribution of classes, the original dataset and thus training set is imbalanced. Though this reflects reality where there are less occurrences of wine with poor quality (of grades 3 or 4) or wine of good quality (of grades 7 or 8), the unequal distribution may affect the accuracy of our classification models, in which the models are biased towards the classes with a higher number of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg.fit(x_train, y_train)\n",
    "y_pred = logReg.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred, labels=[3,4,5,6,7,8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, when we look at the confusion matrix of the logistic regression model built earlier, the model predicted none of the minority classes (grades 3, 4 or 8) despite there being such samples in the test set. Instead, the model predicts quality as mostly 5 or 6 when actual grade is 3, 4, or 8 (e.g. 2 samples of grade 3 were predicted as quality 5). This suggests that there may be some bias present in our models.\n",
    "\n",
    "As we are interested in not just wine of grades 5 or 6 but across the entire scale, we would like our models to be able to predict the minority classes as well. \n",
    "\n",
    "In dealing with an imbalanced dataset, different data sampling techniques can be employed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling \n",
    "Firstly, we attempt to undersample the majority classes in our training dataset, i.e. reduce the number of samples or observations from the majority classes, using the RandomUnderSampler from imblearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# using a dict to define the no. of samples for each class\n",
    "# reduce the no. of samples for quality 5, 6 and 7 to 100\n",
    "under_strategy = {3:8, 4:40, 5:100, 6:100, 7:100, 8:13}\n",
    "under = RandomUnderSampler(sampling_strategy=under_strategy, random_state=0)\n",
    "x_train_resampled, y_train_resampled = under.fit_resample(x_train, y_train)\n",
    "\n",
    "# check distribution of classes after undersampling\n",
    "counter = Counter(y_train_resampled)\n",
    "print(counter)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy score and confusion matrix of LogReg model after undersampling\n",
    "\n",
    "logReg.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = logReg.predict(x_test)\n",
    "print('For Logistic Regression, accuracy score: %s' %accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression as an example, we notice from the confusion matrix that after undersampling the majority classes, the model is able to better predict the minority classes -- predicting correctly 3 samples of grade 4 (previously 0) and 39 samples of grade 7 (previously 14). However, accuracy score has fallen from 0.625 to 0.5475 as the number of incorrect predictions for the majority classes has increased. This suggests a tradeoff, in which heavily undersampling the majority classes have resulted in information loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling \n",
    "Next, we attempt to oversample the minority classes in our training dataset instead, i.e. increase the number of samples or observations from the minority classes. The Synthetic Minority Oversampling Technique (SMOTE) is used to synthesize new samples from existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# using a dict to define the no. of samples for each class\n",
    "# increase the no. of samples for quality 3, 4, 7 and 8\n",
    "over_strategy = {3:30, 4:120, 5:511, 6:478, 7:180, 8:40}\n",
    "over = SMOTE(sampling_strategy=over_strategy, random_state=0, k_neighbors=3)\n",
    "x_train_resampled, y_train_resampled = over.fit_resample(x_train, y_train)\n",
    "\n",
    "# check distribution of classes after oversampling\n",
    "counter = Counter(y_train_resampled)\n",
    "print(counter)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy score and confusion matrix of LogReg model after oversampling\n",
    "\n",
    "logReg.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = logReg.predict(x_test)\n",
    "print('For Logistic Regression, accuracy score: %s' %accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, using logistic regression as an example, we notice from the confusion matrix that after oversampling the majority classes, the model is able to better predict the minority classes. Accuracy for the model remained at 0.625, and further experimentation with the sampling strategy (no. of samples for minority classes after oversampling) did not boost accuracy as well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Undersampling and Oversampling\n",
    "Next, we attempt to combine undersampling and oversampling techniques to evaluate the impact of data sampling on the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomOverSampler and BorderlineSMOTE, a variation of SMOTE intended for oversampling of multi-class datasets \n",
    "# were also looked at.\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "over_strategy = {3:30, 4:70, 5:511, 6:478, 7:160, 8:40}\n",
    "under_strategy = {3:30, 4:70, 5:420, 6:400, 7:160, 8:40}\n",
    "over = BorderlineSMOTE(sampling_strategy=over_strategy, random_state=0, k_neighbors=3)\n",
    "under = RandomUnderSampler(sampling_strategy=under_strategy, random_state=0)\n",
    "# over = RandomOverSampler(sampling_strategy=over_strategy,random_state=0)\n",
    "\n",
    "pipeline = Pipeline(steps=[('o', over), ('u', under)])\n",
    "\n",
    "x_train_resampled, y_train_resampled = pipeline.fit_resample(x_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_resampled)\n",
    "print(counter)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Using Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy score and confusion matrix of LogReg model based on resampled data\n",
    "logReg.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = logReg.predict(x_test)\n",
    "print('For Logistic Regression, accuracy score: %s' %accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-NN Classification Using Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy score and confusion matrix of K-NN model based on resampled data\n",
    "\n",
    "# Finding k with the highest accuracy for values in k_array\n",
    "k_max = 0\n",
    "ac_max = 0\n",
    "for k in k_array:\n",
    "    knn_ex = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_ex.fit(x_train_resampled,y_train_resampled)\n",
    "    ac = accuracy_score(y_test,knn_ex.predict(x_test))\n",
    "    if (ac > ac_max):\n",
    "        k_max = k\n",
    "        ac_max = ac\n",
    "    print(\"K =\", k, \"and accuracy =\", ac)\n",
    "print(\"----------\")\n",
    "print(\"The number of neighbours with the best accuracy for K-NN is\", k_max, \"of accuracy\", ac_max)\n",
    "\n",
    "# Model K-NN with k that has best accuracy \n",
    "knn_1 = KNeighborsClassifier(n_neighbors=k_max)\n",
    "knn_1.fit(x_train_resampled,y_train_resampled)\n",
    "y_pred = knn_ex.predict(x_test)\n",
    "print(\"----------\")\n",
    "print('For K-NN, accuracy score: %s' %accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Using Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(x_train_resampled, y_train_resampled)\n",
    "y_pred = dt.predict(x_test)\n",
    "print('For Decision Tree, accuracy score: %s' %accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a combination of oversampling and undersampling techniques have enabled the models to predict minority classes better, but generally, accuracy of the models fell (LogReg: from 0.625 to 0.595, K-NN: from 0.515 to 0.485, DT: maintained at 0.6275) due to other factors such as information loss for the majority classes. It is noted however, that the decision tree model receives greater benefits from data sampling out of the three classification models used, as the tradeoff in accuracy for better predictions for minority classes is less significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact of Data Engineering (Data Sampling)\n",
    "Despite the attempts to resample the dataset using various techniques, accuracy scores of the models have not improved although the models are able to better predict the minority classes. Often, the models predict the majority classes worse after resampling. It is likely that a combination of factors, including enormous data imbalance, extremely low availablity of samples for minority classes and poor correlation between the dependent variables and independent variable have limited the learning of the classification models. Attempts to remove the bias resulting from imbalanced dataset have resulted in tradeoffs such as information loss instead. More data, especially for the minority classes are required for the models to learn better and give better predictions for all classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering - Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look into feature engineering. More specifically, we will use feature selection to reduce the number of features to be used for training our classification models. The curse of dimensionality becomes more apparent with each additional feature or dimension in the dataset. It results in high data sparsity and may unnecessarily increase storage space and processing time for a modelling algorithm. As such, we only want to keep independent variables that are sufficiently correlated with the dependent variable and also make sure that the independent variables in the model are not strongly correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we look at the correlation matrix of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = df.corr()\n",
    "\n",
    "# Plot the heatmap of the correlation matrix\n",
    "plt.figure(figsize=(13,9))\n",
    "ax = sns.heatmap(data=corr_mat, annot=True, annot_kws={\"weight\": \"bold\"})\n",
    "plt.title(\"Correlation Matrix for red wine quality dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter candiate features by checking their correlation with respect to the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our potential candidates for features in our model are features that have an absolute value of correlation > 0.3 with respect to the dependent variable, quality. We will now take a look at these candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on column of the corr matrix that shows correlation with respect to the dependent variable\n",
    "target_label = \"quality\"\n",
    "target_column = corr_mat[target_label]\n",
    "\n",
    "# Drop the row of the target_column which shows the correlation of the dep variable with respect to itself\n",
    "target_column.drop([target_label], inplace=True)\n",
    "\n",
    "# Define lower bound of the correlation of indep variable with respect to the dependent variable\n",
    "corr_y_lower_bound = 0.3\n",
    "\n",
    "# Filter candidate features using the defined lower bound\n",
    "candidate_features = target_column[abs(target_column) > corr_y_lower_bound]\n",
    "print(\"Features that have |corr| > %s with %s:\\n%s\\n\" % (corr_y_lower_bound, target_label, candidate_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter candidate features by checking their correlation with respect to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering out the potential candidates using the lower bound of 0.3, we are left with 2 candidates, namely, volatile acidity and alcohol. Now, we check if these features are strongly correlated with each other. If they are, we keep the feature which has the highest correlation with the dependent variable, quality, and remove the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_drop = list(set(corr_mat.index) - set(candidate_features.index))\n",
    "\n",
    "# Drop columns and indexes that are not candidate features\n",
    "new_corr_mat = corr_mat.drop(index=labels_to_drop, columns=labels_to_drop)\n",
    "\n",
    "print(\"%s\\n\" % new_corr_mat)\n",
    "\n",
    "skip = []\n",
    "selected = []\n",
    "\n",
    "print(\"%s\\n\" % list(new_corr_mat.columns))\n",
    "\n",
    "# Define lower bound of the correlation of dep variable with respect to dependent variable\n",
    "corr_x_lower_bound = 0.3\n",
    "counter = 1\n",
    "\n",
    "for col in list(new_corr_mat.columns):\n",
    "    if not (col in skip or col in selected):\n",
    "        print(\"---------------------Pass %s---------------------\\n\" % counter)\n",
    "        \n",
    "        # Find the features / x which are highly correlated to each other\n",
    "        temp = new_corr_mat[col]\n",
    "        temp = temp[abs(temp) > corr_x_lower_bound]\n",
    "        print(\"Features that have |corr| > %s with %s:\\n%s\\n\" % (corr_x_lower_bound, col, temp))\n",
    "        \n",
    "        # Select one from amongst them that has the highest correlation to y as their representative\n",
    "        corr_wrt_y_for_strongly_corr_features = candidate_features[temp.index]\n",
    "        print(\"Correlation with respect to y for features that have |corr| > %s with %s:\\n%s\\n\" %\n",
    "              (corr_x_lower_bound, col, corr_wrt_y_for_strongly_corr_features))\n",
    "        max_corr_with_y_feature = corr_wrt_y_for_strongly_corr_features.abs().idxmax()\n",
    "        print(\"Feature that is most correlated with y:\\n%s\\n\" % max_corr_with_y_feature)\n",
    "        selected.append(max_corr_with_y_feature)\n",
    "        print(\"Current selected features = %s\\n\" % selected)\n",
    "        \n",
    "        # Skip over the other features since we already have a representative for them\n",
    "        skip.extend(list(set(corr_wrt_y_for_strongly_corr_features.index) - set([max_corr_with_y_feature])))\n",
    "        print(\"Current features to skip = %s\\n\" % skip)\n",
    "        counter = counter + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selected for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the output of the preceding cell, the candidate features do not have an absolute value of correlation of > 0.3 with respect to each other. Hence, the features we will be using in our model are the following features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_selected = df[selected]\n",
    "\n",
    "x_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the data for 2 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are only using 2 features in our new model, we are now able to visualise the data of the independent variables in the form of a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot of volatile acidity and alcohol\n",
    "\n",
    "plt.figure(figsize=(14, 8), dpi=80)\n",
    "\n",
    "for quality in np.unique(y):\n",
    "    x_by_quality = x_selected.values[y == quality]\n",
    "    plt.scatter(x=x_by_quality[:, 0], \n",
    "                y=x_by_quality[:, 1],\n",
    "                label=\"Quality = \" + str(quality))\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Scatter plot of volatile acidity vs alcohol')\n",
    "plt.xlabel(x_selected.columns[0])\n",
    "plt.ylabel(x_selected.columns[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models using the dataset with only the selected features, namely, volatile acidity and alcohol, are detailed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x_selected\n",
    "\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y, random_state = 0)\n",
    "\n",
    "x2_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression after Feature Engineering (Accuracy: 0.59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training set\n",
    "\n",
    "logReg2 = LogisticRegression (solver = 'lbfgs', multi_class = 'auto', random_state = 0, max_iter = 8000)\n",
    "# The maximum number of iterations has been raised as the default 100 iterations is insufficient \n",
    "# for model to converge given the multiple classes and features\n",
    "\n",
    "start_time = time.time()\n",
    "logReg2.fit(x2_train, y2_train)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "print('For Logistic Regression (post-feature engineering), training the model takes %s seconds.'%time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model using the test dataset\n",
    "# Calculate the duration for prediction and the accuracy of the model\n",
    "\n",
    "start_time = time.time()\n",
    "y2_pred = logReg2.predict(x2_test)\n",
    "end_time = time.time()\n",
    "time_taken = end_time -start_time\n",
    "accuracy = accuracy_score(y2_test, y2_pred)\n",
    "print('For Logistic Regression (post-feature engineering), prediction takes %s seconds.'%time_taken)\n",
    "print('For Logistic Regression (post-feature engineering), accuracy score: %s' %accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model's confusion matrix\n",
    "confusion_matrix (y2_test, y2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN Classification after Feature Engineering (Accuracy: 0.5775)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding k with the highest accuracy for values in k_array\n",
    "\n",
    "k_max = 0\n",
    "ac_max = 0\n",
    "\n",
    "for k in k_array:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(x2_train, y2_train)\n",
    "    y2_pred = knn.predict(x2_test)\n",
    "    accuracy = accuracy_score(y2_test, y2_pred)\n",
    "    if (accuracy != 1) and (accuracy > ac_max):\n",
    "        ac_max = accuracy\n",
    "        k_max = k\n",
    "    print(\"k:\", k, \" and accuracy:\",accuracy)\n",
    "    \n",
    "print(\"--------------\")\n",
    "print(\"The number of neighbours with the best accuracy for K-NN is\", k_max, \"of accuracy\", ac_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model K-NN with k = 7 neighbours\n",
    "knn_1 = KNeighborsClassifier(n_neighbors=k_max)\n",
    "\n",
    "start_time = time.time()\n",
    "knn_1.fit(x2_train,y2_train)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"For K-NN (post-feature engineering), training the model takes %s seconds.\" %time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validate the model using the test dataset\n",
    "# Calculate the duration for prediction and the accuracy of the model\n",
    "start_time = time.time()\n",
    "y2_pred = knn_1.predict(x2_test)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "accuracy = accuracy_score(y2_test, y2_pred)\n",
    "\n",
    "print(\"For K-NN (post-feature engineering), prediction takes %s seconds.\" %time_taken)\n",
    "print(\"For K-NN (post-feature engineering), accuracy score: %s\" %accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the model's confusion matrix\n",
    "confusion_matrix (y2_test, y2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree after Feature Engineering (Accuracy: 0.545)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training set\n",
    "dt = DecisionTreeClassifier(random_state = 0)\n",
    "\n",
    "start_time = time.time()\n",
    "dt.fit(x2_train, y2_train)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"For Decision Tree (post-feature engineering), training the model takes %s seconds\" %time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model using the test dataset\n",
    "# Calculate the duration for prediction and the accuracy of the model\n",
    "start_time = time.time()\n",
    "y2_pred = dt.predict(x2_test)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "accuracy = accuracy_score(y2_test, y2_pred)\n",
    "print(\"For Decision Tree (post-feature engineering), prediction takes %s seconds.\" %time_taken)\n",
    "print(\"For Decision Tree (post-feature engineering), accuracy score: %s\" %accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the model's confusion matrix\n",
    "confusion_matrix (y2_test, y2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the Decision Tree model (after feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the tree, with no output file\n",
    "\n",
    "Source(tree.export_graphviz(dt, out_file=None, class_names=[\"3\", \"4\", \"5\", \"6\", \"7\", \"8\"], \n",
    "                            feature_names= x2_train.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Feature Engineering (Feature Selection)\n",
    "Feature selection has reduced the duration for model training and prediction, especially the former, as the number of features has dropped from 11 to 2. As a result of feature selection, accuracy has dropped for Logistic Regression and Decision Tree models (LogReg: from 0.625 to 0.59, DT: from 0.6275 to 0.545), but increased for K-NN model (K-NN: from 0.515 to 0.5775). \n",
    "\n",
    "This suggests that for this dataset, K-NN model receives the greatest benefit from feature selection out of the three models as the value of k with the best accuracy has decreased significantly from 19 to 7 as well. On the other hand, Decision Tree model has been mostly negatively impacted by feature selection, with a higher drop in accuracy and a wider spread of erroneous predictions across classes based on the confusion matrix. \n",
    "\n",
    "It is worth noting however, that the drop in accuracy for the Logistic Regression and Decision Tree models are not very significant (<0.1). This is in line with the fact that several features or independent variables have poor correlation with the dependent variable and thus have little impact on the results or provide low value to the learning of the models. \n",
    "\n",
    "As the current dataset of 1,599 samples is small, the reduction in training duration may not be significant, except for Logistic Regression model where there was a reduction of several seconds (duration varies depending on machine's processing power). However, if the size of the dataset is much bigger, the benefit of reduced training time as a result of feature selection may outweigh the cost of information loss depending on the chosen model. It is thus worth noting that further experimentation is required with different models and feature selection to determine the most appropriate learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this report, three classification models (Logistic Regression, K-NN and Decision Tree) were applied to the dataset for quality of red wine to investigate the relationship between the independent variables (11 objective attributes of wine) and dependent variable (quality). Data Engineering (data sampling) and Feature Engineering (feature selection) were also conducted to explore if better models can be built. \n",
    "\n",
    "The results however, were not very encouraging. Models on average attained an accuracy score around 0.5 - 0.6, with poor predictions made especially for the minority classes of grades 3, 4 and 8 based on the confusion matrix. There is low correlation between the independent variables and dependent variables, with only 2 independent variables having a Pearson correlation coefficient value of more than 0.3. Data Engineering and Feature Engineering also did not significantly enhance the performance of the models. One possible reason for this is the extremely low number of samples for minority classes - only 10 for grade 3 and 18 for grade 8.\n",
    "\n",
    "Hence, a conclusion on the relationships between red wine attributes and its quality cannot be drawn due to the small dataset. It is uncertain whether consumer preferences can be transformed into measurable indicators for the wine production process or whether aiming for certain levels of the identified attributes (e.g. a specific alcohol level or acidity level) during the wine production process will lead to wine of high quality preferred by consumers. Though it may be argued that consumer preferences and hence wine quality graded by experts are subjective and cannot be learnt or predicted to a great extent by machines, such hypothesis cannot be tested based on the current dataset given the small size. More data, especially for the minority classes, need to be collected for better model training to achieve a more conclusive evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) From this project, we have learned that to achieve an acceptable performance for our machine learning models, large amount of data is required for all classes. Although data sampling can be adopted to mitigate part of the negative effects of an imbalanced dataset, this comes with tradeoffs and the benefits are limited by the size of the original datatset. Moreover, for our machine learning models to be able to make useful predictions, a dataset with independent variables that have a high correlation with the dependent variable is required. Thus, multiple iterations of data collection, sampling and building of the model with various arguments may be necessary to increase the precision of the model.\n",
    "\n",
    "2) With regards to the feature engineering of the dataset, we realise that depending on the dataset, it may be possible to reduce the number of independent variables drastically while having only a marginal drop in the accuracy of our model. This is desirable not only because this helps to reduce the training time of our model, but also because it allows us to visualise the scatter plot of the independent variables (assuming we have only 2 or 3 of them after feature engineering). However, in the context of this project, the reduction in the training time is not substantial (in terms of absolute value) largely due to the size of our dataset.\n",
    "\n",
    "3) Also, among the 3 models, Logistic Regression, K-NN and Decision Tree, there is no objective \"best\" model. The performance of the models largely depend on the nature of the dataset and whether additional techniques such as data sampling or feature selection have been applied to said dataset. Hence, in order to select a suitable classification model, repeated trial and error is sometimes necessary to find the best performing model for a particular dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
